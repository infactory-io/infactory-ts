# End-to-End Quick-Start Scenario

This test is a quickstart test for the Infactory TS SDK.
It will follow the quickstart guide at <https://docs.infactory.ai/quickstart>

The test automates the same path a new user would follow in the UI:  
sign-in → load / rename a project → connect data (`stocks.csv`) → build & deploy
queries → exercise live APIs → explore results → clean up.

### 1. Sign in to Infactory

- **User action**: Open `https://workshop.infactory.ai` and authenticate.
- **Purpose**: Establish a session; retrieve user profile & org context.
- **Endpoint(s)**
  - `GET /v1/authentication/me` (first authenticated request)
- **Done when**: The call returns **200 OK** with a valid user payload.

### 2. Inspect (and optionally rename) the default project

- **User action**: Land in the default project; optionally click its name and
  type something more descriptive.
- **Purpose**: Confirm a writable workspace; improve naming clarity.
- **Endpoint(s)**
  - `GET /v1/projects` – list projects
  - `PATCH /v1/projects/{project_id}` – _only_ if renaming
- **Done when**: Project list contains at least one entry; rename
  returns **200** (or is skipped).

### 3. Create a fresh sandbox project (optional)

- **User action**: Click **New Project**, enter “Campaign Analytics”, press
  **Create**.
- **Purpose**: Demonstrate project-creation flow and isolate test data.
- **Endpoint(s)**
  - `POST /v1/projects`
- **Done when**: Response gives a new `project_id`.

### 4. Open the **Connect** panel

- **User action**: Select **Connect** in the left sidebar.
- **Purpose**: View existing / future data sources.
- **Endpoint(s)**
  - `GET /v1/datasources/project/{project_id}`
- **Done when**: Call returns **200** with an array (often empty).

### 5. Upload `stocks.csv`

- **User action**: Choose **Upload Files**, pick `stocks.csv`.
- **Purpose**: Seed data so queries have something to run on.
- **Endpoint(s)**
  1. `POST /v1/datasources` → returns `datasource_id`
  2. `POST /v1/datasources/{datasource_id}/upload` – file bytes stream
- **Done when**: Upload returns **201**, and ingestion job is queued.

### 6. Wait for schema generation

- **User action**: Observe UI until status flips to **Ready**.
- **Purpose**: Infactory’s AI must infer columns & types before querying.
- **Endpoint(s)**
  - Poll `GET /v1/datasources/{datasource_id}/schema` until `"status":"Ready"`
- **Done when**: Schema response shows column definitions.

### 7. Open the **Build** tab

- **User action**: Click **Build**.
- **Purpose**: Access autogenerated query programs.
- **Endpoint(s)**
  - `GET /v1/queryprograms`
- **Done when**: Response lists ~ 12 starter programs.

### 8. Run an autogenerated query

- **User action**: Select any autogenerated program and press **Run**.
- **Purpose**: Validate read-path and data integrity.
- **Endpoint(s)**
  - `POST /v1/run/queryprogram`
- **Done when**: JSON contains non-empty `rows`.

---

### 9. Create a new query via the AI Assistant

- **User action**: Click **New Query**, open assistant, ask  
  “What’s the ROAS for each campaign?” (or similar).
- **Purpose**: Test natural-language code generation.
- **Endpoint(s)**
  - `POST /v1/build/query_program`
- **Done when**: Response includes generated code & a `queryprogram_id`.

### 10. Execute the new query

- **User action**: Press **Run**.
- **Purpose**: Confirm generated code compiles & executes.
- **Endpoint(s)**
  - `POST /v1/run/queryprogram`
- **Done when**: Result set is returned without error.

---

### 11. Deploy the query as an API

- **User action**: Click **Deploy** in the editor.
- **Purpose**: Expose logic as a REST endpoint.
- **Endpoint(s)**
  - `PATCH /v1/queryprograms/{queryprogram_id}/deploy`
- **Done when**: Response sets `"deployed": true` and returns slug/version.

---

### 12. Browse the **Deploy** catalog

- **User action**: Switch to **Deploy** tab.
- **Purpose**: Retrieve list of live APIs.
- **Endpoint(s)**
  - `GET /v1/apis/project/{project_id}`
- **Done when**: Newly deployed API appears in list.

---

### 13. Test the direct endpoint

- **User action**: In **Live APIs**, fill params if needed and click **Execute**.
- **Purpose**: Verify low-level REST call mirrors query output.
- **Endpoint(s)**
  - `GET /live/{api_slug}/{version}/{endpoint_path}`
- **Done when**: Response data matches step 10.

### 14. Test the unified chat endpoint

- **User action**: Open **Chat Completions**, ask “Top 5 campaigns by ROAS”.
- **Purpose**: Show natural-language routing to deployed queries.
- **Endpoint(s)**
  - `POST /v1/run/{project_id}/chat/completions`
- **Done when**: `choices[0].message.content` contains expected rows.

### 15. Inspect API Logs

- **User action**: Click **API Logs**.
- **Purpose**: Ensure monitoring captures traffic.
- **Endpoint(s)**
  - `GET /v1/projects/{project_id}/api-logs`
- **Done when**: At least two log entries (direct + chat) are present.

---

### 16. Launch the **Explore** chat

- **User action**: Click **+ Explore**.
- **Purpose**: Create a conversational analytics session.
- **Endpoint(s)**
  - `POST /v1/explore` → returns `conversation_id`
- **Done when**: Conversation object is returned.

### 17. Ask an exploratory question

- **User action**: “Show ROAS for each campaign”.
- **Purpose**: Fetch data + auto-generated charts.
- **Endpoint(s)**
  - `POST /v1/run/{conversation_id}`
- **Done when**: Payload includes chart/table info.

---

### 18. Interact with the visualization

- **User action**: Hover bars, export PNG/CSV, etc.
- **Purpose**: Confirm graph endpoint supplies viz data.
- **Endpoint(s)**
  - `GET /v1/explore/{conversation_id}/graph`
- **Done when**: Graph JSON returns **200**.

### 19. Clean up resources (optional)

- **User action**: Delete datasource and sandbox project.
- **Purpose**: Keep tenant clean for repeatable tests.
- **Endpoint(s)**
  - `DELETE /v1/datasources/{datasource_id}`
  - `DELETE /v1/projects/{project_id}`
- **Done when**: Both calls return **204 No Content**.

### Success Criteria Summary

- Every call above returns a **2xx** status.
- Query data is non-empty and consistent across UI, direct, and chat endpoints.
- API Logs show the expected traffic.
- Cleanup removes all test artifacts without error.
